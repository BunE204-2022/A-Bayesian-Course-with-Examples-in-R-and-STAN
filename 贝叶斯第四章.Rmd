---
title: "贝叶斯第四章"
author: "王珞宇 202222011180"
date: "2022-11-04"
output: html_document
---

## **引入**

-   本章将介绍贝叶斯程序的线性回归，并以正态分布（高斯分布）来展现测量的不确定性（$\varepsilon$在线性回归模型中是假定服从正态分布的），因此我们首先来了解正态分布。

## **4.1 为什么正态分布随处可见？**

**4.1.1 通过加法得到正态分布**

1.  假设有一千个人站在足球场的中线，每个人手中都有一枚质地均匀的硬币；

2.  每个人投掷硬币16次。若硬币正面朝上，则向左移动一步；反面朝上则向右移动一步；（这里步长设置为1以内）

3.  投掷16次结束后，测量每个人离中线的距离，得到距离的总分布。

R语言实现如下：

```{r}
pos <- replicate(1000, sum(runif(16, -1, 1))) 
#runif：生成16个（-1，1）均匀分布上的随机数
#sum：求生成16个随机数的和
#replicate：重复sum 1000次

#数据可视化
plot(density(pos)) #绘制密度图

```

随着投掷硬币的次数增多，该分布将越来越接近正态分布。这里我们还需注意到这个实例里面潜在分布是一个投掷硬币的二项分布，最终呈现出的距离分布是正态分布，究竟是什么原因呢？

-   任何将同一分布的随机性相加的过程都会收敛为正态。

    也就是说样本的**随机性之间可以相互抵消**，样本数量越多，这些随机性能被抵消的概率越大，这也是为什么大样本的分布很多时候都趋于正态分布的原因。

    此外，**潜在分布拥有什么形状并不重要**。可以是均匀分布，也可以是其他任何分布。根据潜在分布的不同，收敛（抵消）的速度不同。

**4.1.2 通过相乘得到正态分布**

1.  一个生物体的生长速度受到十几个基因座的影响，每个基因座都有几个等位基因可以编码更多的生长;

2.  所有这些基因组都相互影响，每个都能使生长速度提高一个百分比;

3.  这些基因对生物生长的影响是相乘的，而不是相加。

```{r}
 prod( 1 + runif(12,0,0.1) )
#在1.0和1.1之间随机抽取12个数字，每个数字代表增长的比例。1.0意味着没有额外的增长，1.1意味着10%的 增长。所有12个数字的乘积被计算出来并作为输出返回。
#prod() 函数用于返回其参数中存在的所有值的乘法结果

#生成10000个结果看看是什么分布
growth <- replicate( 10000 , prod( 1 + runif(12,0,0.1) ) )
plot(density(growth))

```

为什么相乘效应也能显示出正态分布呢？

-   小数的乘法作用与加法大致相同。例如，如果有两个位点的等位基因各增加了10%的生长，那么乘积就是$$1.1×1.1=1.21=(1+0.1)(1+0.1)=1+0.2+0.01≈1.2$$如果小数点后面的数字越小，这种加法近似的效果就越好，因此它们也趋向于稳定在高斯分布上。

```{r}
#比较小数点后面数字大小对近似加法作用的影响
big <- replicate( 10000 , prod( 1 + runif(12,0,0.5) ) ) #偏移量0.5
small <- replicate( 10000 , prod( 1 + runif(12,0,0.01) ) ) #偏移量0.1
plot(density(big))
plot(density(small))

```

**4.1.3 通过相乘取对数得到正态分布**

前面说到较大偏离量相乘并不产生高斯分布，但有些倾向于产生对数尺度上的高斯分布。比如：

```{r}
log.big <- replicate( 10000 , log(prod(1 + runif(12,0,0.5)))) #取对数
plot(density(log.big))
```

-   取对数后较大偏差的"相乘"的形式会变成"相加"的形式，从而产生正态分布。

**4.1.4 使用高斯分布**

-   世界上充满了高斯分布，测量误差、增长的变化和分子的运动速度都倾向于高斯分布。之所以如此，是因为他们的核心都是把波动加在一起，使其相互抵消。

-   指数、伽马、泊松分布等一样普遍且常见，高斯分布并不是唯一分布。如果我们对于分布的先验信息只有平均值和方差，或许高斯分布是一个合理的分布推测。

**反思：**厚尾。高斯分布有一些很好的特性，但将其作为默认的数据分布模型也有一些风险：高斯分布的尾部非常细------数据落入其中的概率非常小。但许多自然（和非自然）过程产生极端事件的概率很高。一个真实而重要的例子是金融时间序列------股票市场的涨跌在短期内看起来是高斯的，但在中长期内，极端的冲击使高斯模型并不适用。

**更进一步：**了解高斯分布的概率密度函数 $$p(y|\mu,\sigma)=\frac{1}{\sqrt{2\pi \sigma ^{2}}}exp(-\frac{(y-\mu )^2}{2\sigma ^2})$$

**还有另一种形式**，将$\sigma$替换为$\tau$，这里$\tau=1/\sigma^2$被称为精度，则概率密度函数为$$p(y|\mu,\sigma)=\sqrt{\frac{\tau }{2\pi }}exp\left ( -\frac{1}{2} \tau (y-\mu )^2\right )$$

## **4.2 使用简明的语言描述模型**

例如：重新描述投掷地球的模型：$$W\sim Binominal(N,p) ; P\sim Uniform(0,1)$$

-   其中W是观察到的水的数量，N是抛掷的总次数，p是地球上水覆盖所占的比例。

-   一旦我们以这种表达方式知道了这个模型，我们就会自然知道它的所有假设。我们知道二项分布假设每个样本（抛球）都是独立于其他样本的，所以我们也知道该模型假设样本点是相互独立的。

-   p定义了先验参数。

**更进一步：**从模型定义到贝叶斯定理。为了把上面的数学表达式与贝叶斯定理联系起来，可以用下式来定义后验分布。$$Pr(p|w,n)=\frac{Binomimal(w|n,p)Uniform(p|0,1)}{\int Binomial(w|n,p)Uniform(p|0,1)dp}$$

```{r}
#网格逼近，后验概率的分布
w <- 6; n <- 9; 
p_grid <- seq(from=0,to=1,length.out=100)
posterior <- dbinom(w,n,p_grid)*dunif(p_grid,0,1)
posterior <- posterior/sum(posterior)
plot(posterior)

```

## **4.3 身高的高斯分布**

**4.3.1 数据**

载入纳米比亚桑人部落人口数据，对身高进行分析。

```{r}
library(rethinking)
data(Howell1)
d <- Howell1
precis( d ) #rethinking包summary的功能

#提取身高变量,用$
#d$height

#选取成年人数据
d2 <- d[ d$age >= 18 , ] #对“年龄”产生作用
```

**4.3.2 模型**

```{r}
dens(d2$height)
```

-   典型的身高数据是趋近于高斯分布的，因为身高是许多小生长因子的总和。但选用模型时不能因为样本分布像高斯分布就选高斯分布模型进行分析；同时也须知道，潜在分布就算不是高斯分布，例如前面举例的二项分布，也能形成高斯分布。

我们把身高服从正态分布写为如下形式：$$h_i\sim Normal(\mu,\sigma)$$

其实还有另一种写法，但很少用：$$h_i=\mu+\epsilon_i,\epsilon_i\sim Normal(0,\sigma)$$

为了完成这个模型，需要一些先验参数。要估计的参数是μ和σ，所以我们需要一个先验$Pr(\mu, \sigma)$，即所有参数的联合先验概率。在大多数情况下，每个参数的先验是独立的，这相当于假设$Pr(\mu,\sigma) = Pr(\mu) Pr(\sigma)$.因此可以得到

$$h_i\sim Normal(\mu,\sigma)（似然函数）$$

$$\mu\sim Normal(178,20)（\mu的先验）$$

$$\sigma\sim Uniform(0,50)（\sigma的先验）$$

-   先行预测性模拟是建模的一个重要部分,它可以帮我们排除一些不好的先验假设。同时我们需要记住，先验不是基于样本数据中的数值，而是基于在看到样本数据之前对总体的了解。

-   在此，我们考察先验假设的$\mu$和$\sigma$的分布。

```{r}
curve( dnorm(x, 178, 20) , from=100 , to=250 )
curve( dunif(x, 0, 50) , from=-10 , to=60 )
```

接下来通过随机取样来模拟身高的概率密度曲线：

```{r}
sample_mu <- rnorm(10000, 178, 20) #10000次正态随机抽样，均值178，标准差20
sample_sigma <- runif(10000, 0, 50) #10000次[0,50]上均匀分布抽样
prior_h <- rnorm(10000, sample_mu, sample_sigma)
dens(prior_h)
```

贝叶斯公式表述为：$$Pr(\mu,\sigma\mid h)=\frac{\Pi_iNormal(h_i\mid\mu,\sigma)Normal(\mu\mid178,20)Uniform(\sigma\mid0,50)}{\iint\Pi_iNormal(h_i\mid\mu,\sigma)Normal(\mu\mid178,20)Uniform(\sigma\mid0,50)d\mu d\sigma}$$

**4.3.3 网格逼近**

网格逼近------探寻后验分布的形状

1.什么是网格逼近？

通过将参数区域划分成有限个网格逼近连续的后验分布，对于每一个参数的取值$p_i$，只需要计算后验概率，即$p_i$对应的先验概率×似然函数值除平均似然，在每一个网格上取一个参数值计算相应的后验概率能够大致逼近后验分布。

2.步骤：

（1）定义网格：你决定用多少个点估计后验概率，然后创建网格上所有参数值的一个列表。

（2）计算网格上每个参数值的先验概率。

（3）计算每个参数值的似然函数。

（4）计算每个参数值的非标准后验概率，通过用似然度乘以先验概率。

（5）通过用每个值除以所有值的和得到标准化后验概率。

```{r}
mu.list <- seq( from=150, to=160 , length.out=100 ) 
sigma.list <- seq( from=7 , to=9 , length.out=100 )
#构造一个数据框，将各参数的各水平完全搭配
post <- expand.grid( mu=mu.list , sigma=sigma.list ) 
#对每个数据组合算对数似然函数
post$LL <- sapply( 1:nrow(post) , function(i) sum(
  dnorm( d2$height , post$mu[i] , post$sigma[i] , log=TRUE ) ) )
#计算每个参数值的非标准后验概率，这里是对数，所以相乘变为了相加
post$prod <- post$LL + dnorm( post$mu , 178 , 20 , TRUE ) + 
  dunif( post$sigma , 0 , 50 , TRUE )
#标准化
post$prob <- exp( post$prod - max(post$prod) )

#可视化
image_xyz( post$mu , post$sigma , post$prob )

```

**4.3.4 从后验分布中抽取样本**

为了更详细地研究这个后验分布，我们将再次从分布中抽取参数值。这就像在第三章中一样，从掷地球的例子的后验分布中抽出p的值时。不同的是这里有两个参数，我们需要对它们的组合进行抽样，我们首先按照post\$prob中的数值比例随机抽出post中的行号。然后再找到这行中的均值和方差。

```{r}
#在所有后验结果中随机抽取10000个样本，重复抽样，按每个参数组合对应的后验概率值进行抽取
sample.rows <- sample( 1:nrow(post) , size=10000 , replace=TRUE ,prob=post$prob )
#抽取该样本对应的均值和方差
sample.mu <- post$mu[ sample.rows ]
sample.sigma <- post$sigma[ sample.rows ]
#可视化：plot(横坐标，纵坐标，点的大小，点的形状，透明度参数)
plot( sample.mu , sample.sigma , cex=0.5 , pch=16 , col=col.alpha(rangi2,0.1) )
```

-   看出从高度数据后验分布抽取的样本，点的密度在中间最高，反映了µ和σ的最合理的组合。

```{r}
#尾部值
PI( sample.mu )
PI( sample.sigma )

dens( sample.sigma )
```

-   $\sigma$分布的右偏性：因为这个参数设定为≥0，它可以无限大，但不能无限小。因此在实际问题中很大可能呈现右偏分布。

**4.3.5 二次逼近**

-   如果仅仅是处理单个参数的后验分布，使用网格逼近就可以解决。但有些现实问题往往存在多个参数，如果计算2个参数100个值的网格，需要$100^2$次。

-   由前面的图形可以观察到，靠近后验概率分布峰值的区域大致符合高斯分布，这意味着我们可以使用高斯分布进行估计。

-   高斯分布的对数像一条抛物线，而抛物线是二次函数，所以该方法称为二次逼近。

该方法有两个步骤：

1）寻找后验分布模式。这通常可以由一些优化算法完成------称为"爬坡"的过程，因为后验分布就像一座山一样，算法不知道峰值在哪，但它已经知道它走过的坡度。

2）一旦找到后验分布的峰值，需要估计峰值附近的曲率，这个曲率用来计算整个后验分布的二次逼近。

```{r}
#选出成年人数据
library(rethinking)
data(Howell1)
d <- Howell1
d2 <- d[ d$age >= 18 , ]
#将数据存入alist
#alist允许你做一个任意的R对象的集合,但不会执行代码，list会执行。所以当定义一个公式的列表时，你应该使用alist，这样代码就不会被执行。当你定义一个参数起始值的列表时，你应该使用list，这样像mean(d2$height)这样的代码就会被视为一个数字值。
flist <- alist(height ~ dnorm( mu , sigma ),
               mu ~ dnorm( 178 , 20 ) ,
               sigma ~ dunif( 0 , 50 )
               )
#二次逼近，这里没有设置初始值，他是随机的
m4.1 <- quap( flist , data=d2 )
precis( m4.1 )

#设置初始值
start <- list(mu=mean(d2$height),
              sigma=sd(d2$height))
mm4.1 <- quap( flist , data=d2 , start=start )
precis( mm4.1 )
```

这些结果为每个参数的边际分布提供了高斯近似值。同时展示了89%兼容区间（compatibility interval)的边界。

前面给出的$\mu$的数据所包含的有用信息是很少的，因为它的标准差太大，接下来我们缩小$\mu$的标准差，让他能包含更大的信息量。

```{r}
m4.2 <- quap(
  alist(height ~ dnorm( mu , sigma ) ,
        mu ~ dnorm( 178 , 0.1 ) ,
        sigma ~ dunif( 0 , 50 )
        ) , data=d2 )

precis( m4.2 )
```

这里注意到，与前面相比，对µ的后验估计几乎没有脱离先验信息。先验是非常集中在178附近。但是也要注意，σ的估计值变化很大，尽管我们根本没有改变它的先验信息。一旦统计模型确定平均值在178附近--那么就必须以这个事实为条件来估计σ。这导致了对σ的不同后验结果，尽管我们改变的只是关于$\mu$的先验信息。

**4.3.6 从二次逼近结果中抽样** 上面解释了如何使用quap来获得后验的二次近似。但如何从二次近似后验分布中获得样本呢？

1.方差-协方差矩阵：

对一个具有多个参数维度的后验分布的二次近似--µ和σ各贡献一个维度--可以看作一个多维的高斯分布。引入多维高斯分布，就不仅需要均值和方差数据，还需要协方差数据。

```{r}
#方差—协方差矩阵
vcov(m4.1)

#mu和sigma的方差，开根号能得到precis中sd的结果
diag( vcov( m4.1 ) )

#协方差矩阵，自身相关系数为1，和另外一个参数的相关系数接近0，验证了mu和sigma独立，但实际中很罕见。
cov2cor( vcov( m4.1 ) )
```

2.在多维高斯分布中抽取向量：

```{r}
#在二次逼近得到的数据m4.1中抽取10000个样本
library(rethinking)
post <- extract.samples( m4.1 , n=10000 )

#上述操作将得到10000行两列的数据，均值列的均值方差&方差列的均值方差会和二次逼近的结果很接近
precis(post)
plot(post,cex=0.5 , pch=16 , col=col.alpha(rangi2,0.1))

#和之前网格逼近的图进行比较
```

**更进一步：**前面我们只用到了简单抽样extract.samples，还可以用从多维高斯分布中抽样的代码语句mvrnorm：

```{r}
library(MASS)
post_1 <- mvrnorm( n=10000 , mu=coef(m4.1) , Sigma=vcov(m4.1) )
plot(post_1,cex=0.5 , pch=16 , col=col.alpha(rangi2,0.1))
```

## **4.4 线性预测**

通常情况下，我们感兴趣的是建立一个变量与其他一些变量即预测变量的关系模型。如果预测变量与响应变量有任何统计上的关联，那么就可以用他们来预测结果。当预测变量和响应变量以一种特定的方式建立起模型关系时，我们就会得到线性回归模型。

**反思：什么是回归？**

"回归"这个术语意味着使用一个或多个预测变量来模拟一个或多个响应变量的分布。该术语源于人类学家弗朗西斯------高尔顿（1822-1911）的观察，即高个子和矮个子的儿子都倾向于靠近身高平均值，因此"回归"可以理解为向其平均值靠近。

**4.4.1 线性模型策略**

-   接着上面的例子，我们来考察身高（响应变量）与体重（预测变量）的线性关系。

```{r}
library(rethinking)
data(Howell1)
d <- Howell1
d2 <- d[ d$age >= 18 , ]
plot( d2$height ~ d2$weight )

```

先前的例子中我们有：

$$h_i\sim Normal(\mu,\sigma)（似然函数）$$

$$\mu\sim Normal(178,20)（\mu的先验）$$

$$\sigma\sim Uniform(0,50)（\sigma的先验）$$

现在，我们将体重变量用$x$表示。为了将体重变量纳入模型，我们将平均值$\mu$定义为$x$的函数。：

$$h_i\sim Normal(\mu_i,\sigma)（似然函数）$$

$$\mu = \alpha + \beta(x_i - \bar x)（线性模型）$$

$$\alpha\sim Normal(178,20)（alpha先验）$$

$$\beta\sim Normal(0,10)（beta先验）$$

$$\sigma\sim Uniform(0,50)（\sigma的先验）$$

-   线性模型：

    平均数µ不再是一个需要估计的参数。相反，从模型的第二行可以看出，µi是由参数α和β以及观察到的变量x构建的。这一行不代表随机关系------其中没有∼，而是一个=，因为µi的定义是确定性的。也就是说，一旦我们知道了α、β和xi，我们就能确定地知道µi。α称为截距项，β称为斜率项。

    单位问题：标准化 or 无单位分析

-   $\beta$

```{r}
#set.seed()用于设定随机数种子，一个特定的种子可以产生一个特定的伪随机序列，这个函数的主要目的是让模拟能重复出现，因为很多时候我们需要取随机数，但这段代码再跑一次的时候，结果就不一样了，如果需要重复出现同样的模拟结果的话，就可以用set.seed()，括号里的是编号。
set.seed(2971)
N <- 100 # 100 lines
a <- rnorm( N , 178 , 20 )
b <- rnorm( N , 0 , 10 )

plot( NULL , xlim=range(d2$weight) , ylim=c(-100,400) ,
      xlab="weight" , ylab="height" )
abline( h=0 , lty=2 ) #h画水平线，=后是截距；lty是线条类型
abline( h=272 , lty=1 , lwd=0.5 ) #lwd是线条宽度
mtext( "b ~ dnorm(0,10)" ) #指定文字出现的位置
xbar <- mean(d2$weight) #体重的平均值
#绘制图像
for ( i in 1:N ) curve( a[i] + b[i]*(x - xbar) ,
                        from=min(d2$weight) , to=max(d2$weight) ,
                        add=TRUE,col=col.alpha("black",0.2) )

```

这个模式看起来不符合人类群体的特征。它本质上说，体重和身高之间的关系可能是正相关或负相关。在我们还没有看到数据的时候，这是一个很糟糕的模型假设。我们能做得更好吗？

我们知道，在一定程度上，平均身高随着平均体重的增加而增加。我们试着把$\beta$限制在正值。最简单的方法是把先验定义为对数正态。$$\beta\sim Log-Normal(0,1)$$

```{r}
#对数正态的随机数
b <- rlnorm( 10000 , 0 , 1 )
dens( b , xlim=c(0,5) , adj=0.1 )

set.seed(2971)
N <- 100 # 100 lines
a <- rnorm( N , 178 , 20 )
b <- rlnorm( N , 0 , 1 )

plot( NULL , xlim=range(d2$weight) , ylim=c(-100,400) ,
      xlab="weight" , ylab="height" )
abline( h=0 , lty=2 ) #h画水平线，=后是截距；lty是线条类型
abline( h=272 , lty=1 , lwd=0.5 ) #lwd是线条宽度
mtext( "log(b) ~ dnorm(0,1)" ) #指定文字出现的位置
xbar <- mean(d2$weight) #体重的平均值
#绘制图像
for ( i in 1:N ) curve( a[i] + b[i]*(x - xbar) ,
                        from=min(d2$weight) , to=max(d2$weight) ,
                        add=TRUE,col=col.alpha("black",0.2) )

```

在后面的章节中可以看到因为该样本数据足够多，先验信息可能并不是很重要，但不是所有样本的数据都足够多，在样本数据量较少的情况下进行先验信息的可视化验证很重要。

**4.4.2 寻找后验分布**

我们所要做的就是将新的平均数模型纳入quap的模型中，并为新的参数β添加一个先验。重复一下模型的定义，现在右边是相应的R代码：

$$h_i\sim Normal(\mu_i,\sigma),height\sim dnorm(mu,sigma)$$

$$\mu = \alpha + \beta(x_i - \bar x),(mu <- a+b*(weight-xbar))$$

$$\alpha\sim Normal(178,20),a\sim dnorm(178,20)$$

$$\beta\sim Normal(0,10),b\sim dlnorm(0,1)$$

$$\sigma\sim Uniform(0,50),\sigma\sim dunif(0,50)$$

```{r}
#载入数据
library(rethinking)
data(Howell1)
d <- Howell1
d2 <- d[ d$age >= 18 , ]
#定义体重的平均数x-bar
xbar <- mean(d2$weight)
# fit model
m4.3 <- quap(
  alist(
    height ~ dnorm( mu , sigma ) ,
    mu <- a + b*( weight - xbar ) ,
    a ~ dnorm( 178 , 20 ) ,
    b ~ dlnorm( 0 , 1 ) ,
    sigma ~ dunif( 0 , 50 )
    ) , data=d2 )
```

**4.4.3 解释后验分布**

```{r}
precis( m4.3 )
```

**让我们把重点放在b (β)上，因为它是一个新参数**：

-   由于β是一个斜率，数值0.90可以理解为体重增加1公斤，身高预计会高0.90厘米。

-   89%的后验概率位于0.84和0.97之间。这表明β值接近于零或大于1与这个模型不兼容。

-   这个结果当然不是证明体重和身高之间的关系是线性的，因为这个模型只考虑他们之间的线性性。它只是说明如果你认为身高和体重的关系是线性的，那么斜率在0.9左右是可信的。

我们将从原始数据和一条拟合线开始。下面的代码绘制了原始数据，计算了a和b的后验平均值和拟合直线。

```{r}
#以厘米为单位的身高（垂直）与以公斤为单位的体重（水平）相比较，后验平均线以黑色标出。
plot( height ~ weight , data=d2 , col=rangi2 )
post <- extract.samples( m4.3 )
a_map <- mean(post$a)
b_map <- mean(post$b)
curve( a_map + b_map*(x - xbar) , add=TRUE )
```

**增加平均值的不确定性：**

-   后验平均线只是是后验分布所考虑的无数条线中最合理的一条。像上图这样的平均线图，对于了解一个变量的估计影响的大小是很有用的，但它们对不确定性的表现很差。

-   后验分布考虑了连接身高和体重的每一条可能的回归线。它给每个a,b组合都分配了一个相对可信度。这意味着a和b的每个组合都有一个后验概率。

**那么，我们怎样才能把这个不确定因素放到图上呢？**

-   α和β的组合一起定义了一条线。因此，我们可以从后验分布中抽出**一堆线**。然后我们可以在图上显示这些线，以可视化回归关系中的不确定性。

```{r}
#取前十个样本
N <- 10
dN <- d2[ 1:N , ]
mN <- quap(
  alist(height ~ dnorm( mu , sigma ) ,
        mu <- a + b*( weight - mean(weight) ) ,
        a ~ dnorm( 178 , 20 ) ,
        b ~ dlnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 50 )
        ) , data=dN )

#展示20条线来查看其不确定性
post <- extract.samples(mN, n=20)
# 展示原始数据和抽取的样本个数
plot( dN$weight , dN$height ,
      xlim=range(d2$weight) , ylim=range(d2$height) ,
      col=rangi2 , xlab="weight" , ylab="height" )
mtext(concat("N = ",N))
#展示20个a,b的不同组合，用for循环进行
for ( i in 1:20 )
  curve( post$a[i] + post$b[i]*(x-mean(dN$weight)) ,
         col=col.alpha("black",0.3) , add=TRUE )

#尾部的不确定性更大

N <- 100
dN <- d2[ 1:N , ]
mN <- quap(
  alist(height ~ dnorm( mu , sigma ) ,
        mu <- a + b*( weight - mean(weight) ) ,
        a ~ dnorm( 178 , 20 ) ,
        b ~ dlnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 50 )
        ) , data=dN )

#展示20条线来查看其不确定性
post <- extract.samples(mN, n=20)
# 展示原始数据和抽取的样本个数
plot( dN$weight , dN$height ,
      xlim=range(d2$weight) , ylim=range(d2$height) ,
      col=rangi2 , xlab="weight" , ylab="height" )
mtext(concat("N = ",N))
#展示20个a,b的不同组合，用for循环进行
for ( i in 1:20 )
  curve( post$a[i] + post$b[i]*(x-mean(dN$weight)) ,
         col=col.alpha("black",0.3) , add=TRUE )
#随着样本量的增加，回归线图变得更加紧凑。这是模型对平均值的位置越来越有信心的结果。

```

**绘制回归区间和等值线**

我们暂时把注意力集中在一个单一的体重值上，比如50公斤。可以通过使用后验分布样本，迅速为一个体重为50公斤的人列出10000个μ值。

```{r}
post <- extract.samples( m4.3 )
mu_at_50 <- post$a + post$b * (50 - xbar)
```

由于a和b的联合计算，这些平均值的变化包含了两个参数的不确定性和相关性。在这一点上，实际绘制这个平均数向量的密度可能会有帮助：

```{r}
dens( mu_at_50 , col=rangi2 , lwd=2 , xlab="mu|weight=50" )
#兼容区间
PI( mu_at_50 , prob=0.89 )
```

-   当体重为50公斤时，抽取平均身高μ的二次逼近样本的后验分布。这个分布代表了平均数不同数值的相对可信度（概率）。

-   由a和b的分布是高斯的，所以µ的分布也是高斯的（高斯分布相加产生一个高斯分布）。

我们需要对线性图示上横轴上的每一个重量值重复上述计算，并在平均斜率周围画出89%的区间。

```{r}
#函数link为我们输入的每个案例提供了一个μ的后验分布
#一般默认是从二次逼近后验分布中抽取1000个样本
#(link在这里可以理解成特殊的后验分布抽样)
#post <- extract.samples(m4.3)
#mu.link <- function(weight) post$a + post$b*( weight - xbar )
#weight.seq <- seq( from=25 , to=70 , by=1 )
#mu <- sapply( weight.seq , mu.link ),sapply一次性对一堆数据执行某个函数
mu <- link( m4.3 )
str(mu) #紧凑的显示对象内部结构
```

上面我们有一个原始数据中每个人的µ分布。但实际上，我们想要的东西略有不同：我们想要线性模型横轴上每个体重值的µ分布。

```{r}
#将横轴的体重数据分成间距为1的数据
weight.seq <- seq( from=25 , to=70 , by=1 )
mu <- link( m4.3 , data=data.frame(weight=weight.seq) )
str(mu)

#可视化
#按照d2数据设定图像横纵坐标并隐藏原始数据
plot( height ~ weight , d2 , type="n" ) #type=n，隐藏原始数据

#
for ( i in 1:100 )
points( weight.seq , mu[i,] , pch=16 , col=col.alpha(rangi2,0.1) )

#对每个体重值的分布进行总结。我们将使用apply，它可以选择的函数应用于一个矩阵。
mu.mean <- apply( mu , 2 , mean )  #算每一列mu的均值;1代表计算行,2代表计算列
mu.PI <- apply( mu , 2 , PI , prob=0.89 ) #mu的89%区间

#把原始数据显示出来
plot( height ~ weight , data=d2 , col=col.alpha(rangi2,0.5) )

#画出最优拟合线
lines( weight.seq , mu.mean )

#89%的区间
shade( mu.PI , weight.seq )
```

**总结画置信区间的步骤：**

(1) 使用link()生成µ的后验值分布。link默认使用原始数据，所以必须把想要绘制的后验预测的新横轴值列表传递给它。

(2) 使用总结函数apply，及平均数、PI，为预测变量的每个值找到平均数和µ的下限和上限。

(3) 最后，使用线条和阴影等绘图函数来绘制直线和区间。

**89%的预测区间（区别置信区间）**

最开始对于$h_i$的统计模型如下：$$h_i\sim Normal(\mu_i,\sigma)$$到目前为止，我们所做的只是用后验的样本来可视化μi的不确定性，即平均值的线性模型。但是对高度的实际预测也取决于σ，所有这些都表明我们需要以某种方式将σ纳入预测中。

```{r}
#从后验分布中取包含了sigma的身高值可以采用sim
sim.height <- sim( m4.3 , data=list(weight=weight.seq) )
str(sim.height)

#他跟前面的mu很像，但他加入了不确定性
#post <- extract.samples(m4.3)
#weight.seq <- 25:70
#sim.height <- sapply( weight.seq , function(weight)
#rnorm(
#n=nrow(post) ,
#mean=post$a + post$b*( weight - xbar ) ,
#sd=post$sigma ) )

#同样我们可以用apply及图像画出来它的样子

height.PI <- apply( sim.height , 2 , PI , prob=0.89 )
plot( height ~ weight , d2 , col=col.alpha(rangi2,0.5) )
lines( weight.seq , mu.mean )
shade( mu.PI , weight.seq )
shade( height.PI , weight.seq )
```

注意到宽阴影区间的轮廓有点粗糙，这是高斯分布尾部大方差导致的。可以增加后验分布中抽取的样本数使其更平滑。sim.height的可选参数n可以控制使用多少个样本。

```{r}
sim.height1 <- sim( m4.3 , data=list(weight=weight.seq) , n=10000 )
height.PI1 <- apply( sim.height1 , 2 , PI , prob=0.89 )

plot( height ~ weight , d2 , col=col.alpha(rangi2,0.5) )
lines( weight.seq , mu.mean )
shade( mu.PI , weight.seq )
shade( height.PI1 , weight.seq )
```

## **4.5 从直线到曲线**

这章将介绍两种使用线性回归来构建曲线的常用方法：1.多项式回归；2.B-spline。这两种方法都是通过将一个预测变量转化为几个合成变量来工作的。

**4.5.1 多项式回归**

多项式回归使用一个预测变量的幂------平方或立方，作为额外的预测因素。这是一种建立曲线回归的简单方法。我们用下面的例子来理解多项式回归是如何工作的：

```{r}
library(rethinking)
data(Howell1)
d <- Howell1
plot( height ~ weight , d)
```

最常见的多项式回归是均值的抛物线模型。设x是标准化的体重。那么平均身高的抛物线方程为：$$\mu_i = \alpha + \beta_1x_i + \beta_2x_i^2$$ $\alpha$+$\beta_1x_i$部分与线性回归中x的线性函数相同，附加项使用xi的平方来构建抛物线，新参数$\beta_2$测量关系的曲率。

拟合一个身高与体重的抛物线模型，首先要做的是将预测变量标准化。因为多项式回归中存在平方或者立方项，当预测变量中的数值非常大时，有时会出现数字上的故障，标准化在很大程度上解决了这个问题。

为了定义抛物线模型，只需修改µi的定义：

$$h_i\sim Normal(\mu_i,\sigma)$$

$$\mu_i = \alpha + \beta_1x_i + \beta_2x_i^2$$

$$\alpha\sim Normal(178,20)$$

$$\beta_1\sim Log-Normal(0,1)$$

$$\beta_2\sim Normal(0,1)$$

$$\sigma\sim Uniform(0,50),\sigma\sim dunif(0,50)$$

```{r}
#展示多项回归的均值区间和预测区间
d$weight_s <- ( d$weight - mean(d$weight) )/sd(d$weight) #标准化
d$weight_s2 <- d$weight_s^2 #平方项
#二次逼近的后验分布
m4.5 <- quap(
  alist(
    height ~ dnorm( mu , sigma ) ,
    mu <- a + b1*weight_s + b2*weight_s2 ,
    a ~ dnorm( 178 , 20 ) ,
    b1 ~ dlnorm( 0 , 1 ) ,
    b2 ~ dnorm( 0 , 1 ) ,
    sigma ~ dunif( 0 , 50 )
    ) , data=d )
precis( m4.5 )

#绘制图形
weight.seq <- seq( from=-2.2 , to=2 , length.out=30 )
pred_dat <- list( weight_s=weight.seq , weight_s2=weight.seq^2 )

mu <- link( m4.5 , data=pred_dat )
mu.mean <- apply( mu , 2 , mean )
mu.PI <- apply( mu , 2 , PI , prob=0.89 )

sim.height <- sim( m4.5 , data=pred_dat )
height.PI <- apply( sim.height , 2 , PI , prob=0.89 )

plot( height ~ weight_s , d , col=col.alpha(rangi2,0.5) )
lines( weight.seq , mu.mean )
shade( mu.PI , weight.seq )
shade( height.PI , weight.seq )

```

```{r}
#下面展示含x立方项的模型图形
d$weight_s3 <- d$weight_s^3
m4.6 <- quap(
  alist(
    height ~ dnorm( mu , sigma ) ,
    mu <- a + b1*weight_s + b2*weight_s2 + b3*weight_s3 ,
    a ~ dnorm( 178 , 20 ) ,
    b1 ~ dlnorm( 0 , 1 ) ,
    b2 ~ dnorm( 0 , 10 ) ,
    b3 ~ dnorm( 0 , 10 ) ,
    sigma ~ dunif( 0 , 50 )
    ) , data=d )

weight.seq <- seq( from=-2.2 , to=2 , length.out=30 )
pred_dat3 <- list( weight_s=weight.seq , weight_s2=weight.seq^2,
                   weight_s3=weight.seq^3)

mu3 <- link( m4.6 , data=pred_dat3 )
mu.mean3 <- apply( mu3 , 2 , mean )
mu.PI3 <- apply( mu3 , 2 , PI , prob=0.89 )

sim.height3 <- sim( m4.6 , data=pred_dat3 )
height.PI3 <- apply( sim.height3 , 2 , PI , prob=0.89 )

plot( height ~ weight_s , d , col=col.alpha(rangi2,0.5) )
lines( weight.seq , mu.mean3 )
shade( mu.PI3 , weight.seq )
shade( height.PI3 , weight.seq )

#如果我们不想要标准化体重，想要变为原始体重数据，可以做以下操作：
plot( height ~ weight_s , d , col=col.alpha(rangi2,0.5) , xaxt="n" )
at <- c(-2,-1,0,1,2)
labels <- at*sd(d$weight) + mean(d$weight)
axis( side=1 , at=at , labels=round(labels,1) )

```

**这里需要明确的是：**

我们并不清楚这些模型中的任何一个是否有很大的意义。

-   它们确实很好地拟合了样本数据，但对样本更好地拟合可能实际上不是一个更好的模型；

-   同时该模型不包含任何生物信息：身高和体重之间的没有因果关系。

这些问题都会在后续章节进行讨论。

**4.5.2 Spline（广义加性模型）**

```{r}
library(rethinking)
data(cherry_blossoms)
d <- cherry_blossoms
precis(d)
```

我们的目标是用一个**摆动的函数**来逼近开花的趋势。

-   与多项式回归不同的是，B-splines并不直接通过对预测变量进行平方或立方的转换。

-   相反，它创造了一系列全新的、合成的预测变量。每个合成变量的存在只是为了在真实预测变量的特定范围内逐渐打开和关闭一个特定的参数。

-   每个合成变量都被称为一个基础函数。这个线性模型可以用下列式子表示：$$\mu_i = \alpha + w_1B_i,_1+ w_2B_i,_2+ w_3B_i,_3 + ...$$

-   其中$B_i,_n$是第n个基础函数在第i行的值；

-   w参数是每个基础函数的相应权重。

这些参数就像斜率一样，调整每个基础函数对平均值μi的影响(spline模型中体现为曲线的摆动程度)。因此，这实际上只是另一种线性回归。

**我们如何构建这些基础变量B？**

作者在图4.12中展示了最简单的情况，他用线性近似的组合对开花日期的数据进行了近似。

首先，他将横轴的全部范围分为四个部分，使用称为节点的支点。节点在图中用+符号表示；

节点作为五个不同的基础函数的支点，即我们的B变量。这些合成变量被用来使函数图像从横轴的一个区域温和地过渡到下一个区域。从上图的左边开始，基础函数1的值为1，其他的都被设置为0。当我们向右移动到第二个节点时，基础函数1下降，基础函数2增加。在第2个节点上，基础函数2的值为1，而其他所有的都被设置为0。

这些基础函数的好处是使每个参数的影响相当局部。在图4.12中横轴上的任何一点，只有两个基础函数有非零值。如图中蓝色虚线显示的是1200年的情况。该年的基函数1和2都是非零的。因此，基函数1和2的参数是影响1200年预测的唯一参数。这与多项式回归完全不同，在多项式回归中，参数影响整个曲线的形状。

![](images/%E5%BC%80%E8%8A%B1.jpg)

下图作者显示了每个基础函数乘以其相应的权重参数所得到的图形。权重参数可以是正的，也可以是负的。因此，可以看出基础函数5的权重是负数，因为他最终在零线以下。

![](images/%E5%BC%80%E8%8A%B12.jpg)

建立代码，重现上图。首先，我们选择节点。在这个案例中，节点是年的数值，它应该放在哪里？

原则上，你可以把节点放在任何你喜欢的地方，它们的位置是模型的一部分，你要对它们负责。让我们像上面的简单例子那样，把节点放在预测变量的不同均匀的量级上。这样，在有更多观测数据的地方就会有更多的结点。在第一个例子中，我们只用了5个节点。接下来我们使用15个节点：

```{r}
d2 <- d[ complete.cases(d$doy) , ]
num_knots <- 15
knot_list <- quantile( d2$year , probs=seq(0,1,length.out=num_knots) )

library(splines)
B <- bs(d2$year,
knots=knot_list[-c(1,num_knots)] ,
degree=3 , intercept=TRUE )

plot( NULL , xlim=range(d2$year) , ylim=c(0,1) , xlab="year" , ylab="basis" )
for ( i in 1:ncol(B) ) lines( d2$year , B[,i] )
```

```{r}
m4.7 <- quap(
  alist(
    D ~ dnorm( mu , sigma ) ,
    mu <- a + B %*% w ,
    a ~ dnorm(100,10),
    w ~ dnorm(0,10),
    sigma ~ dexp(1)  #使用了指数先验,对于simga这类需要大于0的规模参数是有用的先验
    ), data=list( D=d2$doy , B=B ) ,
start=list( w=rep( 0 , ncol(B) ) ) )

post <- extract.samples( m4.7 )
w <- apply( post$w , 2 , mean )
plot( NULL , xlim=range(d2$year) , ylim=c(-6,6) ,
      xlab="year" , ylab="basis * weight" )
for ( i in 1:ncol(B) ) lines( d2$year , w[i]*B[,i] )

mu <- link( m4.7 )
mu_PI <- apply(mu,2,PI,0.97)
plot( d2$year , d2$doy , col=col.alpha(rangi2,0.3) , pch=16 )
shade( mu_PI , d2$year , col=col.alpha("black",0.5) )
```
